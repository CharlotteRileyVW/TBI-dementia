{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Cognitive Decline in TBI Patients With Factors Such As Mental Illness and Drug Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charlotte Riley-Vanwagoner\n",
    "\n",
    "Amelia Le\n",
    "                                       \n",
    "Lonnie Schneider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traumatic brain injury (TBI) is a condtion that affects approximately 2.8 million people each year in the United States. TBI is increasing among all populations however there is a concerning rise in particular, in people who play contact sports, military personel (combat and non-combat blast injuries) and general traumatic incidences such as automobile accidents. Importantly, there are no current treatments for chronic TBI however, there are large initiatives targeting biomarkers and other potential mechanistic targets. It is currently thought that a primary reason for the lack of treatment options for TBI is that diagnosis and prognosis for TBI are often nebulous, unable to clearly define injury types and severities. Chronnic traumatic encephalopathy(CTE) is a form of neurodegeneration that has become apparent in people who suffer repeated mild concussive injuries. Mild injuries such as concussions are often misdiagnosed and/or not adressed in a clinical setting at all. It is understood that repeated head injuries often lead to neurodegeneration later in life, as well as progressive associated comorbidities such as emotional problems, suicideality and dementia. Currently there are large data sets that have been amassed to identify biomarkers for prognosis for TBI and to understand its pathological progression to dementia however they remain under-utilized. \n",
    "\n",
    "This project aims to analyze a subset of these data from a federally conserved database called the Federal Interagency Traumatic Brain Injury Research inforamtics center (FITBIR) to identify and predict multivariate biomarkers such as mental illness and drug use to aid in the prognosis of TBI and CTE. This will lead to increased understanding of the pathogenesis of CTE and improved treatment accuracy. This study will also contribute to the elucidation of the timeline for the development of dementia and other co-morbidities post injury.\n",
    "\n",
    "https://fitbir.nih.gov/ \n",
    "\n",
    "This is where we collected our data sets from. We have narrowed the datasets down to imaging data, pediatric data, biomarker data, cognitive data, and neurodegeneration data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some ethical considerations to be made about this project. The first one is that only authorized personal are allowed to access the data from the FITBIR website. Luckily, Lonnie has access to this data because he is an authorized personel. If this wasn't the case, then it would be unethical to use this data if we were not allowed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree, svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GUID</th>\n",
       "      <th>dizziness</th>\n",
       "      <th>1</th>\n",
       "      <th>AUDTTScore</th>\n",
       "      <th>AcuteAssesmtsEvaluationDayNum</th>\n",
       "      <th>AcuteAssessmt PlateletTransfusionInd</th>\n",
       "      <th>AcuteAssessmtCryoprecipitateTransfusionInd</th>\n",
       "      <th>AcuteAssessmtEEGMonitoringStat</th>\n",
       "      <th>AcuteAssessmtFactor 7TransfusionInd</th>\n",
       "      <th>AcuteAssessmtFresh frozen plasma (FFP)TransfusionInd</th>\n",
       "      <th>...</th>\n",
       "      <th>preOpioid</th>\n",
       "      <th>preSedative</th>\n",
       "      <th>preStimulant</th>\n",
       "      <th>race</th>\n",
       "      <th>residentType</th>\n",
       "      <th>sex</th>\n",
       "      <th>surgeryAdverse</th>\n",
       "      <th>sweating</th>\n",
       "      <th>urinaryDiscomfort</th>\n",
       "      <th>vomiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TBI_INVAB423TUR</td>\n",
       "      <td>No</td>\n",
       "      <td>Complete Scores--Valid</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No or not stated</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Private home, apartment or condominium</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TBI_INVAB826GR0</td>\n",
       "      <td>No</td>\n",
       "      <td>Complete Scores--Valid</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No or not stated</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Private home, apartment or condominium</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBI_INVAC020WPA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unable to finish</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No or not stated</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Private home, apartment or condominium</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TBI_INVAC153CWH</td>\n",
       "      <td>No</td>\n",
       "      <td>Complete Scores--Valid</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No or not stated</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Private home, apartment or condominium</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TBI_INVAC275CGJ</td>\n",
       "      <td>No</td>\n",
       "      <td>Complete Scores--Valid</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No or not stated</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Private home, apartment or condominium</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GUID  dizziness                       1  AUDTTScore  \\\n",
       "0  TBI_INVAB423TUR         No  Complete Scores--Valid         2.0   \n",
       "1  TBI_INVAB826GR0         No  Complete Scores--Valid         2.0   \n",
       "2  TBI_INVAC020WPA         No        Unable to finish         0.0   \n",
       "3  TBI_INVAC153CWH         No  Complete Scores--Valid         3.0   \n",
       "4  TBI_INVAC275CGJ         No  Complete Scores--Valid         2.0   \n",
       "\n",
       "   AcuteAssesmtsEvaluationDayNum AcuteAssessmt PlateletTransfusionInd  \\\n",
       "0                            2.0                                   No   \n",
       "1                            3.0                                   No   \n",
       "2                            7.0                                   No   \n",
       "3                            2.0                                   No   \n",
       "4                            5.0                                   No   \n",
       "\n",
       "  AcuteAssessmtCryoprecipitateTransfusionInd AcuteAssessmtEEGMonitoringStat  \\\n",
       "0                                         No               No or not stated   \n",
       "1                                         No               No or not stated   \n",
       "2                                         No               No or not stated   \n",
       "3                                         No               No or not stated   \n",
       "4                                         No               No or not stated   \n",
       "\n",
       "  AcuteAssessmtFactor 7TransfusionInd  \\\n",
       "0                                  No   \n",
       "1                                  No   \n",
       "2                                  No   \n",
       "3                                  No   \n",
       "4                                  No   \n",
       "\n",
       "  AcuteAssessmtFresh frozen plasma (FFP)TransfusionInd   ...    preOpioid  \\\n",
       "0                                                 No     ...          1.0   \n",
       "1                                                 No     ...          1.0   \n",
       "2                                                 No     ...          1.0   \n",
       "3                                                 No     ...          1.0   \n",
       "4                                                 No     ...          1.0   \n",
       "\n",
       "  preSedative preStimulant                       race  \\\n",
       "0         1.0          1.0  Black or African American   \n",
       "1         1.0          1.0                      White   \n",
       "2         1.0          1.0                      Asian   \n",
       "3         1.0          1.0                      White   \n",
       "4         1.0          1.0  Black or African American   \n",
       "\n",
       "                             residentType     sex surgeryAdverse  sweating  \\\n",
       "0  Private home, apartment or condominium    Male             No        No   \n",
       "1  Private home, apartment or condominium  Female             No        No   \n",
       "2  Private home, apartment or condominium  Female             No        No   \n",
       "3  Private home, apartment or condominium    Male             No        No   \n",
       "4  Private home, apartment or condominium    Male            Yes        No   \n",
       "\n",
       "   urinaryDiscomfort vomiting  \n",
       "0                 No       No  \n",
       "1                 No       No  \n",
       "2                 No       No  \n",
       "3                 No      Yes  \n",
       "4                 No       No  \n",
       "\n",
       "[5 rows x 238 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuro_df = pd.read_csv(\"CombinedData20percent.csv\")\n",
    "neuro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro_df = neuro_df.select_dtypes(exclude=['object']) # This is to reduce the numbers of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163\n",
      "1180\n"
     ]
    }
   ],
   "source": [
    "print(neuro_df['StroopTestTimesStroopTestTmPartIVal'].isna().sum())\n",
    "print(neuro_df['StroopTestStroopTestTmPartIIVal'].isna().sum())\n",
    "# Seeing how many NaN values so I can drop the appropriate amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = neuro_df.drop(columns=['StroopTestAssmntCompltNum','StroopTestEvaluationDayNum','StroopTestPTADayDur',\\\n",
    "                                 'StroopTestStudyDayAssmntCompltNum']) # Need to remove these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in clean_df.columns:\n",
    "    #print(name)\n",
    "    #print(clean_df[name].isna().sum())\n",
    "    num_na = clean_df[name].isna().sum()\n",
    "    if num_na > 1180:\n",
    "        #print(\"Drop\")\n",
    "        clean_df = clean_df.drop(columns = name)\n",
    "clean_df = clean_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDTTScore\n",
      "AcuteAssesmtsEvaluationDayNum\n",
      "AdverseEventResolveTime\n",
      "AdverseEventsCOBRITAdvrsEventCodeCOBRIT\n",
      "AdverseEventsCOBRITAdvrsEventNum\n",
      "AdverseEventsCOBRITSWIMSeqNumCOBRIT\n",
      "AlchBldLvlMeasr\n",
      "Alcohol\n",
      "BSI18AnxScoreRaw\n",
      "BSI18AnxScoreT\n",
      "BSI18DeprScoreRaw\n",
      "BSI18DeprScoreT\n",
      "BSI18GSIScoreRaw\n",
      "BSI18GSIScoreT\n",
      "BSI18SomScoreRaw\n",
      "BSI18SomScoreT\n",
      "BldPressrDiastlMeasr\n",
      "BldPressrSystMeasr\n",
      "COBRITTempMeasr\n",
      "COWATAdjustedTotalScore\n",
      "COWATDaysSinceBaseline\n",
      "COWATRawTotalScore\n",
      "CTEpdurlLesnVolMeasr\n",
      "CTIntraparenLesnVolMeasr\n",
      "CTMidlineShiftMeasr\n",
      "CTSbdrlLesnVolMeasr\n",
      "Cannabis\n",
      "Cocaine\n",
      "DaysSinceBaseline\n",
      "DigitSpanAssmntCompltNum\n",
      "DigitSpanDigitSpnBckwrdScore\n",
      "DigitSpanDigitSpnFwrdScr\n",
      "DigitSpanDigitSpnRawScr\n",
      "DigitSpanDigitSpnScldScr\n",
      "DigitSpanEvaluationDayNum\n",
      "DigitSpanPTADayDur\n",
      "GCSDay\n",
      "GCSLeftEyeMeasure\n",
      "GCSMotor\n",
      "GCSRightEyeMeas\n",
      "GCSTotalScore\n",
      "GOATAmnesia\n",
      "GOATCrntTimeScore\n",
      "GOATDayMnthDateScore\n",
      "GOATDayScore\n",
      "GOATDetailScore\n",
      "GOATErrorSumVal\n",
      "GOATFirstEvntScore\n",
      "GOATLastEvntScore\n",
      "GOATMnthScore\n",
      "GOATModeTranspScore\n",
      "GOATPreInjuEventDetailScore\n",
      "GOATTotalScore\n",
      "GOATYearScore\n",
      "GOSEDaysSinceBaseline\n",
      "GlasgowOutcomeScalExtScore\n",
      "Hallucinogen\n",
      "HeartRate\n",
      "HrsBetInjArrCOBRITHospCt\n",
      "HrsBetInjBACCt\n",
      "HrsBetInjCTCt\n",
      "HrsBetInjRandCt\n",
      "Inhalant\n",
      "InjTimeEstimateMinCt\n",
      "LabTestResltVal\n",
      "MedctnCodeCOBRIT\n",
      "O2SatMeasr\n",
      "Opioid\n",
      "PSIAssmntCompltNum\n",
      "PSIDigSymbRawScrCOBRIT\n",
      "PSIDigSymbScldScrCOBRIT\n",
      "PSIEvaluationDayNum\n",
      "PSIPTADayDur\n",
      "PSISpeed IndexPSISymbSrchScldScrCOBRIT\n",
      "PSISymbSrchRawScrCOBRIT\n",
      "PSI_ValidityAssmntCompltNum\n",
      "PTADayDur\n",
      "PTAEvaluationDayNum\n",
      "PTAStudyDayAssmntCompltNum\n",
      "PaO2Measr\n",
      "PulmBloodGasPPCO2Val\n",
      "PulmGasExFIO2Val\n",
      "RespRate\n",
      "SafetyVitalSgnHosplzation\n",
      "SafetyVitalSgnHosplzationSafetyVitalstMntNum\n",
      "SafetyVitalsNum\n",
      "Sedative\n",
      "Stimulant\n",
      "StroopTestStroopTestTmPartIIVal\n",
      "StroopTestTimesStroopTestTmPartIVal\n",
      "Study ID\n",
      "StudyDay_DrugStartNum\n",
      "StudyDay_DrugStopNum\n",
      "TempMeasr\n",
      "TotalInsMeasr\n",
      "TotalOutsMeasr\n",
      "TotalVolHypertonicSalineVal\n",
      "VentilatorSettingRate\n",
      "VitalSignCOBRITAssmntCompltNum\n",
      "VitalSignCOBRITBldPressrDiastlMeasr\n",
      "VitalSignCOBRITBldPressrSystMeasr\n",
      "VitalSignCOBRITEvaluationDayNum\n",
      "VitalSignCOBRITHeartRate\n",
      "VitalSignCOBRITRespRate\n",
      "WgtMeasr\n",
      "age\n",
      "preAlcohol\n",
      "preCannabis\n",
      "preCocaine\n",
      "preHallucinogen\n",
      "preInhalant\n",
      "preOpioid\n",
      "preSedative\n",
      "preStimulant\n"
     ]
    }
   ],
   "source": [
    "for name in clean_df.columns:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only chose the columns that may predict cognitive decline # Filtering columns based off team member Dr. Schneider's suggestions\n",
    "fully_wrangled_df = clean_df.filter(['AdverseEventsCOBRITAdvrsEventNum','BSI18AnxScoreT','BSI18DeprScoreT','BSI18SomScoreT','Cannabis',\\\n",
    "                           'Cocaine','Hallucinogen','Opioid','Sedative', 'Stimulant','StroopTestStroopTestTmPartIIVal',\\\n",
    "                           'StroopTestTimesStroopTestTmPartIVal','WgtMeasr','age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Basic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_wrangled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     73.000000\n",
      "mean      53.219178\n",
      "std       18.987018\n",
      "min       26.000000\n",
      "25%       42.000000\n",
      "50%       49.000000\n",
      "75%       59.000000\n",
      "max      149.000000\n",
      "Name: StroopTestTimesStroopTestTmPartIVal, dtype: float64\n",
      "\n",
      "count     73.000000\n",
      "mean     119.219178\n",
      "std       46.196815\n",
      "min       68.000000\n",
      "25%       91.000000\n",
      "50%      107.000000\n",
      "75%      131.000000\n",
      "max      300.000000\n",
      "Name: StroopTestStroopTestTmPartIIVal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(fully_wrangled_df['StroopTestTimesStroopTestTmPartIVal'].describe())\n",
    "print()\n",
    "print(fully_wrangled_df['StroopTestStroopTestTmPartIIVal'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations [Redacted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redacted because it is not my work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor Variables:\n",
      "[[  2.   65.   61.   48.    1.    2.    1.    2.    1.    1.   90.   27. ]\n",
      " [  1.   49.   44.   42.    1.    1.    1.    1.    1.    1.  141.   60. ]\n",
      " [  3.   38.   42.   49.    4.    1.    1.    1.    1.    1.   90.   53. ]\n",
      " [  1.   39.   45.   48.    1.    1.    1.    1.    1.    1.   74.   18. ]\n",
      " [  1.   60.   65.   66.    1.    1.    1.    1.    1.    1.  110.6  48. ]\n",
      " [  6.    7.   71.   78.    4.    3.    2.    3.    3.    3.   77.   40. ]\n",
      " [  6.   49.   44.   59.    1.    1.    1.    1.    1.    1.   80.   70. ]\n",
      " [  1.   80.   80.   80.    2.    1.    1.    1.    1.    1.   71.4  21. ]\n",
      " [  3.   49.   44.   56.    1.    1.    1.    1.    2.    1.   98.   49. ]\n",
      " [  1.   48.   67.   56.    1.    1.    1.    1.    1.    1.   86.4  26. ]]\n"
     ]
    }
   ],
   "source": [
    "predictor_df = fully_wrangled_df.drop(columns=['StroopTestStroopTestTmPartIIVal', 'StroopTestTimesStroopTestTmPartIVal']) # Need to remove these columns\n",
    "X = predictor_df.values\n",
    "print(\"Predictor Variables:\")\n",
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Scores Dateframe: [ 71.  41.  55.  49.  82.  49.  63.  42.  48.  46. 118.  65.  63.  71.\n",
      "  64.  50.  63.  36.  45.  59. 149.  57.  46.  47.  75.  51.  51.  39.\n",
      "  58.  58.  42.  37.  36.  36.  40.  37.  42.  67.  75.  40.  33.  48.\n",
      "  49.  41.  34.  55.  40.  34.  55.  26.  50.  47.  54.  60.  43.  45.\n",
      "  76.  45.  42.  41.  32.  74.  36.  43.  56.  47.  52.  52.  80.  85.\n",
      "  43.  52.  52.]\n",
      "\n",
      "Binary numpy array for Part 1 Scores:\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "\n",
      "\n",
      "\n",
      "Part2 Scores Dateframe: [191. 111. 120. 128.  94. 120. 201.  87.  88. 112. 218. 221.  99. 135.\n",
      " 131. 124.  91.  96.  93. 145. 180. 300.  92.  86. 113. 113. 140. 112.\n",
      " 111. 141.  75.  91.  80. 103.  95.  76.  86.  98. 175. 109.  77.  96.\n",
      "  84. 131.  96.  99.  81.  68. 179. 100.  75. 113. 155. 157. 100. 108.\n",
      " 129.  80. 176. 131.  76.  79. 102. 107.  86. 112.  99.  83. 300. 135.\n",
      "  91. 126.  91.]\n",
      "\n",
      "Binary numpy array for Part 2 Scores:\n",
      "[1, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# PART 1\n",
    "part1_df = fully_wrangled_df['StroopTestTimesStroopTestTmPartIVal']\n",
    "part1_scores = part1_df.values\n",
    "print(\"Part 1 Scores Dateframe:\", part1_scores)\n",
    "print()\n",
    "\n",
    "# 1 = cognitive issue, 0 = no cognitive issue\n",
    "y = [] # Initializing array\n",
    "for random_number in part1_scores:\n",
    "    if random_number > np.mean(part1_df): # The average score for part 1 is 53.2\n",
    "        #print('cog issue')\n",
    "        y.append(1) # Append to 1 when there is a cognitive deficit\n",
    "    else:\n",
    "        #print('no issue')\n",
    "        y.append(0) # Append to 0 when not popular\n",
    "print(\"Binary numpy array for Part 1 Scores:\")\n",
    "print(y[:10])\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "# PART 2\n",
    "part2_df = fully_wrangled_df['StroopTestStroopTestTmPartIIVal']\n",
    "part2_scores = part2_df.values\n",
    "print(\"Part2 Scores Dateframe:\", part2_scores)\n",
    "print()\n",
    "\n",
    "#1 = cognitive issue, 0 = no cognitive issue\n",
    "cog_eval = [] # This array is to just check if I stored the binary variables properly\n",
    "y2 = [] # Initializing array\n",
    "for random_number in part2_scores:\n",
    "    if random_number > np.mean(part2_df): # The average score for part 2 is 119.2\n",
    "        #print('cog issue')\n",
    "        y2.append(1) # Append to 1 when there is a cognitive deficit\n",
    "    else:\n",
    "        #print('no issue')\n",
    "        y2.append(0) # Append to 0 when not popular\n",
    "print(\"Binary numpy array for Part 2 Scores:\")\n",
    "print(y2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Results for kNN Model\n",
      "[[6 5]\n",
      " [6 2]]\n",
      "Accuracy: 0.42105263157894735\n",
      "Best Accuracy: 0.6658640064212821 with a k value of 9\n",
      "\n",
      "\n",
      "\n",
      "Part 2 Results for kNN Model\n",
      "[[11  2]\n",
      " [ 3  3]]\n",
      "Accuracy: 0.7368421052631579\n",
      "Best Accuracy: 0.6855865153078775 with a k value of 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Results for kNN Model\")\n",
    "X_train_neigh, X_test_neigh, y_train_neigh, y_test_neigh = train_test_split(X, y)\n",
    "kNN_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "kNN_classifier.fit(X_train_neigh, y_train_neigh)\n",
    "kNN_prediction = kNN_classifier.predict(X_test_neigh)\n",
    "print(metrics.confusion_matrix(y_true = y_test_neigh, y_pred = kNN_prediction))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true = y_test_neigh, y_pred = kNN_prediction))\n",
    "\n",
    "# Testing for best accuracy based off of k-value\n",
    "bestk = None\n",
    "largest_average = 0\n",
    "for rn in np.random.randint(1,10,10):\n",
    "    kNN_classifier2 = KNeighborsClassifier(n_neighbors = rn)\n",
    "    kNN_scores2 = cross_val_score(kNN_classifier2, X_train_neigh, y_train_neigh, cv = 3, scoring = 'accuracy')\n",
    "    mean_scores2 = np.mean(kNN_scores2)\n",
    "    if mean_scores2 >= largest_average:\n",
    "        largest_average = mean_scores2\n",
    "        bestk = rn\n",
    "#print(np.mean(best_k_scores))\n",
    "print(\"Best Accuracy:\", largest_average, \"with a k value of\", bestk)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Part 2 Results for kNN Model\")\n",
    "X_train_neigh, X_test_neigh, y_train_neigh, y_test_neigh = train_test_split(X, y2)\n",
    "kNN_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "kNN_classifier.fit(X_train_neigh, y_train_neigh)\n",
    "kNN_prediction = kNN_classifier.predict(X_test_neigh)\n",
    "print(metrics.confusion_matrix(y_true = y_test_neigh, y_pred = kNN_prediction))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true = y_test_neigh, y_pred = kNN_prediction))\n",
    "\n",
    "# Testing for best accuracy based off of k-value\n",
    "bestk = None\n",
    "largest_average = 0\n",
    "for rn in np.random.randint(1,10,10):\n",
    "    kNN_classifier2 = KNeighborsClassifier(n_neighbors = rn)\n",
    "    kNN_scores2 = cross_val_score(kNN_classifier2, X_train_neigh, y_train_neigh, cv = 3, scoring = 'accuracy')\n",
    "    mean_scores2 = np.mean(kNN_scores2)\n",
    "    if mean_scores2 >= largest_average:\n",
    "        largest_average = mean_scores2\n",
    "        bestk = rn\n",
    "#print(np.mean(best_k_scores))\n",
    "print(\"Best Accuracy:\", largest_average, \"with a k value of\", bestk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Results for Decision Tree Model\n",
      "[[6 5]\n",
      " [5 3]]\n",
      "Accuracy: 0.47368421052631576\n",
      "Best Accuracy: 0.4648549478270841 with a depth value of 2 and a min sample of 6\n",
      "\n",
      "\n",
      "\n",
      "Part 2 Results for Decision Tree Model\n",
      "[[11  4]\n",
      " [ 3  1]]\n",
      "Accuracy: 0.631578947368421\n",
      "Best Accuracy: 0.5195505102625845 with a depth value of 6 and a min sample of 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Results for Decision Tree Model\")\n",
    "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(X, y)\n",
    "tree_classifier = tree.DecisionTreeClassifier()\n",
    "tree_classifier.fit(X_train_tree, y_train_tree)\n",
    "tree_prediction = tree_classifier.predict(X_test_tree)\n",
    "print(metrics.confusion_matrix(y_true = y_test_tree, y_pred = tree_prediction))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true = y_test_tree, y_pred = tree_prediction))\n",
    "\n",
    "bestdepth = None\n",
    "bestminsample = None\n",
    "largest_average = 0\n",
    "for _ in range(10):\n",
    "    rn1 = np.random.randint(1, 10)\n",
    "    rn2 = np.random.randint(2, 10)\n",
    "    tree_classifier = tree.DecisionTreeClassifier(max_depth = rn1, min_samples_split = rn2)\n",
    "    tree_scores = cross_val_score(tree_classifier, X_train_tree, y_train_tree, cv = 3, scoring = 'accuracy')\n",
    "    mean_scores = np.mean(tree_scores)\n",
    "    if mean_scores2 >= largest_average:\n",
    "        largest_average = mean_scores\n",
    "        bestdepth = rn1\n",
    "        bestminsample = rn2\n",
    "print(\"Best Accuracy:\", largest_average, \"with a depth value of\", bestdepth, \"and a min sample of\", bestminsample)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Part 2 Results for Decision Tree Model\")\n",
    "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(X, y2)\n",
    "tree_classifier = tree.DecisionTreeClassifier()\n",
    "tree_classifier.fit(X_train_tree, y_train_tree)\n",
    "tree_prediction = tree_classifier.predict(X_test_tree)\n",
    "print(metrics.confusion_matrix(y_true = y_test_tree, y_pred = tree_prediction))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true = y_test_tree, y_pred = tree_prediction))\n",
    "\n",
    "bestdepth = None\n",
    "bestminsample = None\n",
    "largest_average = 0\n",
    "for _ in range(10):\n",
    "    rn1 = np.random.randint(1, 10)\n",
    "    rn2 = np.random.randint(2, 10)\n",
    "    tree_classifier = tree.DecisionTreeClassifier(max_depth = rn1, min_samples_split = rn2)\n",
    "    tree_scores = cross_val_score(tree_classifier, X_train_tree, y_train_tree, cv = 3, scoring = 'accuracy')\n",
    "    mean_scores = np.mean(tree_scores)\n",
    "    if mean_scores2 >= largest_average:\n",
    "        largest_average = mean_scores\n",
    "        bestdepth = rn1\n",
    "        bestminsample = rn2\n",
    "\n",
    "print(\"Best Accuracy:\", largest_average, \"with a depth value of\", bestdepth, \"and a min sample of\", bestminsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 Results for SVM Model\n",
      "[[12  0]\n",
      " [ 7  0]]\n",
      "Accuracy =  0.631578947368421\n",
      "Accuracy with Best C: 0.5546382295608302\n",
      "Best C: 91.76069901828794\n",
      "\n",
      "\n",
      "\n",
      "Part 2 Results for SVM Model\n",
      "[[12  1]\n",
      " [ 5  1]]\n",
      "Accuracy =  0.6842105263157895\n",
      "Accuracy with Best C: 0.6351335855979819\n",
      "Best C: 79.54337006928752\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 1 Results for SVM Model\")\n",
    "Xtrain_svm, Xtest_svm, ytrain_svm, ytest_svm = train_test_split(X, y)\n",
    "SVM_classifier = svm.SVC(kernel='rbf', C= 1, gamma='scale')\n",
    "SVM_classifier.fit(Xtrain_svm, ytrain_svm)\n",
    "SVM_prediction = SVM_classifier.predict(Xtest_svm)\n",
    "print(metrics.confusion_matrix(y_true = ytest_svm, y_pred = SVM_prediction))\n",
    "print('Accuracy = ', metrics.accuracy_score(y_true = ytest_svm, y_pred = SVM_prediction))\n",
    "\n",
    "bestC = None\n",
    "best_average = 0\n",
    "for rn in np.random.uniform(50,100,10):\n",
    "    SVM_classifier2 = svm.SVC(kernel='rbf', C = rn, gamma='scale')\n",
    "    SVM_scores2 = cross_val_score(SVM_classifier2, Xtrain_svm, ytrain_svm, cv = 3, scoring = 'accuracy')\n",
    "    mean_scores = np.mean(SVM_scores2)\n",
    "    if mean_scores >= best_average:\n",
    "        best_average = mean_scores\n",
    "        bestC = rn \n",
    "\n",
    "print(\"Accuracy with Best C:\", (mean_scores))\n",
    "print(\"Best C:\", bestC)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Part 2 Results for SVM Model\")\n",
    "Xtrain_svm, Xtest_svm, ytrain_svm, ytest_svm = train_test_split(X, y2)\n",
    "SVM_classifier = svm.SVC(kernel='rbf', C= 1, gamma='scale')\n",
    "SVM_classifier.fit(Xtrain_svm, ytrain_svm)\n",
    "SVM_prediction = SVM_classifier.predict(Xtest_svm)\n",
    "print(metrics.confusion_matrix(y_true = ytest_svm, y_pred = SVM_prediction))\n",
    "print('Accuracy = ', metrics.accuracy_score(y_true = ytest_svm, y_pred = SVM_prediction))\n",
    "\n",
    "bestC = None\n",
    "best_average = 0\n",
    "for rn in np.random.uniform(50,100,10):\n",
    "    SVM_classifier2 = svm.SVC(kernel='rbf', C = rn, gamma='scale')\n",
    "    SVM_scores2 = cross_val_score(SVM_classifier2, Xtrain_svm, ytrain_svm, cv = 3, scoring = 'accuracy')\n",
    "    mean_scores = np.mean(SVM_scores2)\n",
    "    if mean_scores >= best_average:\n",
    "        best_average = mean_scores\n",
    "        bestC = rn \n",
    "\n",
    "print(\"Accuracy with Best C:\", (mean_scores))\n",
    "print(\"Best C:\", bestC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Part 1 Scores: 0.5068493150684932\n",
      "Accuracy of Part 2 Scores: 0.684931506849315\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "gauss_model = GaussianNB()\n",
    "gauss_model.fit(X, y)\n",
    "gauss_model.predict(X)\n",
    "\n",
    "print(\"Accuracy of Part 1 Scores:\", gauss_model.score(X, y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2)\n",
    "gauss_model = GaussianNB()\n",
    "gauss_model.fit(X, y2)\n",
    "gauss_model.predict(X)\n",
    "print(\"Accuracy of Part 2 Scores:\", gauss_model.score(X, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6986301369863014"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state=0).fit(X, y)\n",
    "logistic_model.predict(X)\n",
    "logistic_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model that achieved the highest accuracy was tied k nearest neighbors. This is most likely due to fact that it was tuned have the most ideal parameters. The best accuracy achieved was .74. This means that the features in our model had a mild significance in predicting cognitive decline in TBI patients.\n",
    "\n",
    "In the future, the model needs to include more observations to have a substantial predictive value. The dataset our team worked with had so many NaNs that made it difficult to have enough data points for modeling. Next time, our team can find large datasets that have complete values so we can have enough data to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned that the presence of mental illness (anxiety, depression) and drug use can increase the chances of a TBI patient experiencing cognitive decline after their injury."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scarpina, F., & Tagini, S. (2017). The Stroop Color and Word Test. Frontiers in psychology, 8, 557. https://doi.org/10.3389/fpsyg.2017.00557\n",
    "\n",
    "https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe\n",
    "\n",
    "All data was retrieved from https://fitbir.nih.gov/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
